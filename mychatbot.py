import streamlit as st
import os
import pandas as pd
import io
from datetime import datetime
from dotenv import load_dotenv

# ë¡œì»¬ ëª¨ë“ˆ import
from data_manager import DataFrameManager, process_data_request
from file_processor import process_uploaded_file
from ai_handler import AIHandler, get_model_templates

load_dotenv()
API_KEY = os.environ.get('OPENAI_APIKEY')

# AI í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
try:
    ai_handler = AIHandler(API_KEY)
except ValueError as e:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_APIKEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# ì±„íŒ… ê¸°ë¡ì„ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []

if "dataframes" not in st.session_state:
    st.session_state.dataframes = {}

if "current_df" not in st.session_state:
    st.session_state.current_df = None

if "df_managers" not in st.session_state:
    st.session_state.df_managers = {}

def main():
    st.set_page_config(
        page_title="ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë§ ê²€ì¦ ì±—ë´‡",
        page_icon="ğŸ’¬",
        layout="wide"
    )
    
    st.title("ğŸ¤– ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë§ ê²€ì¦ ì±—ë´‡")
    st.markdown("---")
    
    # ì•ˆë‚´ ë©”ì‹œì§€
    with st.container():
        st.markdown("""
        ### ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!
        
        ì´ AI ì±—ë´‡ì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
        - ğŸ’¬ **ìì—°ì–´ ëŒ€í™”**: ê¶ê¸ˆí•œ ê²ƒì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”
        - ğŸ“„ **íŒŒì¼ ë¶„ì„**: í…ìŠ¤íŠ¸, CSV, Excel(XLSX), ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ğŸ›ï¸ **ì„¤ì • ì¡°ì ˆ**: ì‚¬ì´ë“œë°”ì—ì„œ AIì˜ ì°½ì˜ì„±ì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        
        ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!
        """)
    
    # ì„œë¹„ìŠ¤ ë²„íŠ¼ë“¤
    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ” ì •ë³´ ê²€ìƒ‰", use_container_width=True):
            st.session_state.messages.append({
                "role": "user", 
                "content": "ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ì•Œê³  ì‹¶ì€ ê²ƒì´ ìˆìœ¼ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
            })
            st.rerun()

    with col2:
        if st.button("ğŸ“Š ë°ì´í„° ë¶„ì„", use_container_width=True):
            if st.session_state.df_managers:
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "ì—…ë¡œë“œëœ ë°ì´í„°ë¡œ í•  ìˆ˜ ìˆëŠ” ì‘ì—…ë“¤ì„ ì•Œë ¤ì£¼ì„¸ìš”."
                })
            else:
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "ë°ì´í„° ë¶„ì„ì´ë‚˜ í•´ì„ì— ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ CSV ë˜ëŠ” Excel(XLSX) íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                })
            st.rerun()
    
    st.markdown("---")
    
    # ë°ì´í„° í¸ì§‘ê¸° ì„¹ì…˜
    if st.session_state.current_df is not None:
        st.subheader("ğŸ“Š ë°ì´í„° í¸ì§‘ê¸°")
        
        # DataFrame ì„ íƒ ì˜µì…˜ (ì—¬ëŸ¬ íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°)
        if len(st.session_state.dataframes) > 1:
            selected_file = st.selectbox(
                "í¸ì§‘í•  ë°ì´í„° íŒŒì¼ ì„ íƒ:",
                options=list(st.session_state.dataframes.keys()),
                key="df_selector"
            )
            if selected_file:
                st.session_state.current_df = st.session_state.dataframes[selected_file]
        
        # ë°ì´í„° í¸ì§‘ê¸° í‘œì‹œ
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("**ğŸ“ ì•„ë˜ì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:**")
        
        with col2:
            if st.button("ğŸ’¾ ë³€ê²½ì‚¬í•­ ì €ì¥", key="save_changes"):
                st.success("âœ… ë³€ê²½ì‚¬í•­ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # ì‹¤ì‹œê°„ í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„° í…Œì´ë¸”
        edited_df = st.data_editor(
            st.session_state.current_df,
            use_container_width=True,
            num_rows="dynamic",  # í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
            key="data_editor",
            height=400
        )
        
        # í¸ì§‘ëœ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„¸ì…˜ì— ë°˜ì˜
        st.session_state.current_df = edited_df
        
        # í˜„ì¬ í¸ì§‘ ì¤‘ì¸ íŒŒì¼ëª… ì—…ë°ì´íŠ¸
        if len(st.session_state.dataframes) > 0:
            current_file_name = list(st.session_state.dataframes.keys())[0] if len(st.session_state.dataframes) == 1 else selected_file
            st.session_state.dataframes[current_file_name] = edited_df
        
        # ë°ì´í„° í†µê³„ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ í–‰ ìˆ˜", len(edited_df))
        with col2:
            st.metric("ì´ ì—´ ìˆ˜", len(edited_df.columns))
        with col3:
            st.metric("ì „ì²´ ì…€ ìˆ˜", len(edited_df) * len(edited_df.columns))
        with col4:
            st.metric("ê²°ì¸¡ê°’", edited_df.isnull().sum().sum())
        
        st.markdown("---")
          
    # ì‚¬ì´ë“œë°” ì„¤ì •
    
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ëª¨ë¸ ì„ íƒ
        st.subheader("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")
        model_templates = get_model_templates()
        
        # ëª¨ë¸ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‘œì‹œ
        selected_model = None
        for category_name, models in model_templates.items():
            # ê¸°ë³¸ì ìœ¼ë¡œ Flagship Chat Modelsë¥¼ í™•ì¥
            expanded = (category_name == "ğŸš€ Flagship Chat Models")
            with st.expander(category_name, expanded=expanded):
                for model_key, model_info in models.items():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        model_name = model_info['name']
                        if model_info.get('deprecated', False):
                            st.write(f"**{model_name}** âš ï¸")
                            st.caption("âš ï¸ " + model_info['description'])
                        else:
                            st.write(f"**{model_name}**")
                            st.caption(model_info['description'])
                        
                        # ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì •ë³´ í‘œì‹œ
                        if 'context_window' in model_info:
                            st.caption(f"ğŸ”— ì»¨í…ìŠ¤íŠ¸: {model_info['context_window']:,} í† í°")
                    
                    with col2:
                        button_disabled = model_info.get('deprecated', False)
                        button_text = "Deprecated" if button_disabled else "ì„ íƒ"
                        if st.button(button_text, key=f"select_{model_key}", disabled=button_disabled):
                            st.session_state.selected_model = model_key
                            st.rerun()
        
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ í‘œì‹œ
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = "gpt-4o"
        
        current_model = st.session_state.selected_model
        
        # í˜„ì¬ ëª¨ë¸ì´ deprecatedì¸ì§€ í™•ì¸
        is_deprecated = False
        for category in model_templates.values():
            if current_model in category:
                is_deprecated = category[current_model].get('deprecated', False)
                break
        
        if is_deprecated:
            st.warning(f"âš ï¸ í˜„ì¬ ëª¨ë¸: **{current_model}** (Deprecated)")
        else:
            st.success(f"âœ… í˜„ì¬ ëª¨ë¸: **{current_model}**")
        
        # ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
        for category in model_templates.values():
            if current_model in category:
                model_info = category[current_model]
                
                # ëª¨ë¸ ì„¸ë¶€ ì •ë³´ë¥¼ ì»¨í…Œì´ë„ˆë¡œ ë¬¶ê¸°
                with st.container():
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("Max Tokens", f"{model_info['max_tokens']:,}")
                        if 'context_window' in model_info:
                            st.metric("Context Window", f"{model_info['context_window']:,}")
                    
                    with col2:
                        streaming_status = "âœ… ì§€ì›" if model_info['supports_streaming'] else "âŒ ë¯¸ì§€ì›"
                        st.metric("ìŠ¤íŠ¸ë¦¬ë°", streaming_status)
                        
                        if 'size' in model_info:
                            st.metric("ëª¨ë¸ í¬ê¸°", model_info['size'])
                
                break
        
        st.divider()
        
        # Temperature ì„¤ì • (o1 ëª¨ë¸ì€ temperature ë¯¸ì§€ì›)
        if not current_model.startswith("o1"):
            temperature = st.slider(
                "ğŸŒ¡ï¸ Temperature", 
                min_value=0.0, 
                max_value=1.0, 
                value=0.7, 
                step=0.1,
                help="ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
            )
        else:
            st.info("ğŸ§  Reasoning ëª¨ë¸ì€ Temperature ì„¤ì •ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            temperature = 1.0  # o1 ëª¨ë¸ì˜ ê¸°ë³¸ê°’
        
        st.divider()
        
        # íŒŒì¼ ì—…ë¡œë“œ
        st.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['txt', 'csv', 'xlsx', 'png', 'jpg', 'jpeg', 'gif'],
            accept_multiple_files=True,
            help="í…ìŠ¤íŠ¸, CSV, Excel(XLSX), ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if uploaded_files:
            st.session_state.uploaded_files = []
            for uploaded_file in uploaded_files:
                file_info, df = process_uploaded_file(uploaded_file)
                st.session_state.uploaded_files.append(file_info)
                st.success(f"âœ… {uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ")
                if df is not None:
                    st.info(f"ğŸ“Š {uploaded_file.name}ì´ í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        st.divider()
        
        ## ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™”
        ## ëŒ€í™” ë©”ì„¸ì§€ ë° íŒŒì¼ ì´ˆê¸°í™”
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.messages = []
            st.session_state.uploaded_files = []
            st.session_state.dataframes = {}
            st.session_state.current_df = None
            st.session_state.df_managers = {}
            st.rerun()
        
        # í†µê³„ ì •ë³´
        st.header("ğŸ“ˆ í†µê³„")
        st.metric("ëŒ€í™” ìˆ˜", len(st.session_state.messages))
        st.metric("ì—…ë¡œë“œëœ íŒŒì¼", len(st.session_state.uploaded_files))
        
        # ëª¨ë¸ ì¹´í…Œê³ ë¦¬ í‘œì‹œ
        current_model = st.session_state.selected_model
        model_category = "ì•Œ ìˆ˜ ì—†ìŒ"
        for category_name, models in model_templates.items():
            if current_model in models:
                model_category = category_name
                break
        st.metric("ëª¨ë¸ ì¹´í…Œê³ ë¦¬", model_category)
    

    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ğŸ’¬ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ë°ì´í„° ì¡°ì‘ ìš”ì²­ ì²˜ë¦¬
        data_result = None
        result_df = None
        
        # í˜„ì¬ í™œì„±í™”ëœ DataFrameManagerê°€ ìˆëŠ”ì§€ í™•ì¸
        current_df_manager = None
        if st.session_state.df_managers:
            # ê°€ì¥ ìµœê·¼ì— ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë§¤ë‹ˆì € ì‚¬ìš©
            latest_file = list(st.session_state.df_managers.keys())[-1]
            current_df_manager = st.session_state.df_managers[latest_file]
            
            # ë°ì´í„° ì¡°ì‘ ìš”ì²­ ì²˜ë¦¬
            data_result, result_df = process_data_request(prompt, current_df_manager)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            # ë°ì´í„° ì¡°ì‘ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ë¨¼ì € í‘œì‹œ
            if data_result and result_df is not None:
                st.markdown(data_result)
                
                # ê²°ê³¼ DataFrame í‘œì‹œ
                st.dataframe(result_df, use_container_width=True)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
                col1, col2 = st.columns(2)
                
                with col1:
                    # ì¡°ì‘ëœ ê²°ê³¼ DataFrameì„ CSVë¡œ ë³€í™˜
                    csv_data = result_df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ",
                        data=csv_data,
                        file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        key=f"csv_{datetime.now().timestamp()}"
                    )
                
                with col2:
                    # ì¡°ì‘ëœ ê²°ê³¼ DataFrameì„ Excelë¡œ ë³€í™˜
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        result_df.to_excel(writer, index=False, sheet_name='Data')
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="ğŸ“Š Excel ë‹¤ìš´ë¡œë“œ",
                        data=excel_data,
                        file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"xlsx_{datetime.now().timestamp()}"
                    )
                
                full_response = data_result
                
                # ë°ì´í„° ì¡°ì‘ íˆìŠ¤í† ë¦¬ í‘œì‹œ
                if current_df_manager and current_df_manager.operation_history:
                    with st.expander("ğŸ” ìˆ˜í–‰ëœ ì‘ì—… íˆìŠ¤í† ë¦¬"):
                        for i, operation in enumerate(current_df_manager.operation_history, 1):
                            st.text(f"{i}. {operation}")
            
            else:
                # ì¼ë°˜ AI ì‘ë‹µ ì²˜ë¦¬
                try:
                    response_stream = ai_handler.get_ai_response(
                        st.session_state.messages,
                        model_name=st.session_state.selected_model,
                        temperature=temperature,
                        uploaded_files=st.session_state.uploaded_files
                    )
                    
                    if isinstance(response_stream, str):
                        # ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš°
                        full_response = response_stream
                        message_placeholder.markdown(full_response)
                    else:
                        # ì„ íƒëœ ëª¨ë¸ì´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
                        model_templates = get_model_templates()
                        supports_streaming = True
                        for category in model_templates.values():
                            if st.session_state.selected_model in category:
                                supports_streaming = category[st.session_state.selected_model]['supports_streaming']
                                break
                        
                        if supports_streaming:
                            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
                            for chunk in response_stream:
                                if chunk.choices[0].delta.content is not None:
                                    full_response += chunk.choices[0].delta.content
                                    message_placeholder.markdown(full_response + "â–Œ")
                            
                            message_placeholder.markdown(full_response)
                        else:
                            # ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ (o1 ëª¨ë¸ë“¤)
                            with st.spinner("ğŸ§  ì¶”ë¡  ì¤‘ì…ë‹ˆë‹¤... (ì´ ëª¨ë¸ì€ ë” ê¹Šì´ ìƒê°í•©ë‹ˆë‹¤)"):
                                full_response = response_stream.choices[0].message.content
                                message_placeholder.markdown(full_response)
                
                except Exception as e:
                    full_response = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    message_placeholder.markdown(full_response)
        
        # AI ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()